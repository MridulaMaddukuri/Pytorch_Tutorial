{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_Basics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MridulaMaddukuri/Pytorch_Tutorial/blob/master/Pytorch_Basics.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "6ICdUmYruulG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pytorch Basics\n",
        "\n",
        "\n",
        "#### 1. What are tensors?\n",
        "#### 2. Creating Tensors\n",
        "#### 3. Tensor Data types\n",
        "#### 4. Indexing Tensors\n",
        "#### 5. Tensor Manipulation \n",
        "#### 6. Operations on tensors\n",
        "#### 7. Matrix/Vector Operations \n",
        "#### 8. Conversion from and to Numpy\n",
        "#### 9. Performance : Numpy arrays vs tensors on CPU vs tensors on GPU\n",
        "#### 10. What are Variables?\n",
        "#### 11. Activation Funtions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vnHyC8P1cI5L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pytorch \n",
        "\n",
        "A Deep Learning framework that provides \n",
        "\n",
        "- Tensors (a replacement for numpy arrays) with strong GPU acceleration \n",
        "- Dynamic Neural Networks (with GPU acceleration)\n",
        "\n",
        "Both features useful in Deep Learning projects \n",
        "\n",
        "\n",
        "#### Comparing with the other popular DL framework: TensorFlow\n",
        "\n",
        "> - Relatively new when compared to ***_TensorFlow_*** but quickly gaining momentum. \n",
        "Easier to adapt to Pytorch due to similarities with numpy.  \n",
        "\n",
        "> - More pythonic \n",
        "\n",
        "> - Offers flexibility to change the NN as you go : change and execute nodes as you go\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "More Pros and Cons can be found in this blog:\n",
        "\n",
        "https://towardsdatascience.com/pytorch-vs-tensorflow-spotting-the-difference-25c75777377b\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "qELA28Gw0JLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "ae3862cc-82a8-4746-b5a1-95918b0dfdf6"
      },
      "cell_type": "code",
      "source": [
        "# install pytorch\n",
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (592.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 592.3MB 45.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.14.6)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-0.3.0.post4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "McyBF-f90RSF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pAFpTbyYzlqP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. What are tensors? \n",
        "\n",
        "A replacement for NumPy to use the power of GPUs "
      ]
    },
    {
      "metadata": {
        "id": "7sEjSilBzpeP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2. Creating Tensors"
      ]
    },
    {
      "metadata": {
        "id": "Dw0bo14HwRNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "850cf5a2-e036-46a5-d8cc-7d335ca83147"
      },
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(2,2)\n",
        "print(\"Shape of tensor x:\" + str(x.shape))\n",
        "print(\"Datatype of x:\" + str(type(x)))\n",
        "print(x) # uninitialized tensor holding garbage values"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of tensor x:torch.Size([2, 2])\n",
            "Datatype of x:<class 'torch.FloatTensor'>\n",
            "\n",
            "1.00000e-19 *\n",
            "  0.0000  0.0000\n",
            "  1.3563  1.3994\n",
            "[torch.FloatTensor of size 2x2]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fTXoNCJb1FsS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "d602a1e9-1a3f-4a6a-a232-6c1b179a9944"
      },
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2) # to make results reproducible\n",
        "\n",
        "\n",
        "x = torch.rand(2,3)  # returns tensor of shape (2,3) filled with random numbers from a uniform distribution on interval [0,1)\n",
        "#torch.rand? # uncomment to know more\n",
        "\n",
        "y = torch.randn(2,3) # returns a tensor of shape (2,3) filled with random numbers from standard normal distribution : mean =0 , variance = 1\n",
        "\n",
        "#torch.randn? # uncomment to know more\n",
        "\n",
        "print(x,y)\n",
        "# if you want these tensors on GPU\n",
        "x,y = x.cuda(),y.cuda()\n",
        "print(x,y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 0.6147  0.3810  0.6371\n",
            " 0.4745  0.7136  0.6190\n",
            "[torch.FloatTensor of size 2x3]\n",
            " \n",
            "-2.1409 -0.5534 -0.5000\n",
            "-0.0815 -0.1633  1.5277\n",
            "[torch.FloatTensor of size 2x3]\n",
            "\n",
            "\n",
            " 0.6147  0.3810  0.6371\n",
            " 0.4745  0.7136  0.6190\n",
            "[torch.cuda.FloatTensor of size 2x3 (GPU 0)]\n",
            " \n",
            "-2.1409 -0.5534 -0.5000\n",
            "-0.0815 -0.1633  1.5277\n",
            "[torch.cuda.FloatTensor of size 2x3 (GPU 0)]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "28Dnz5FpKBKL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "dfeb35b3-bc21-45cf-873e-8a69a78ae0fd"
      },
      "cell_type": "code",
      "source": [
        "# Initialize with a range of values\n",
        "\n",
        "x = torch.arange(5)\n",
        "print(\"arange starting with 0: \")\n",
        "print(x)\n",
        "\n",
        "x = torch.arange(2,20, step = 4)\n",
        "print(\"arange starting with a specific value: \")\n",
        "print(x)\n",
        "\n",
        "\n",
        "\n",
        "# Initialize on a scale\n",
        "x = torch.linspace(0,20, steps = 6) # includes 0 and 20\n",
        "print(\"linspace between a and b with n steps: \")\n",
        "print(x)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arange starting with 0: \n",
            "\n",
            " 0\n",
            " 1\n",
            " 2\n",
            " 3\n",
            " 4\n",
            "[torch.FloatTensor of size 5]\n",
            "\n",
            "arange starting with a specific value: \n",
            "\n",
            "  2\n",
            "  6\n",
            " 10\n",
            " 14\n",
            " 18\n",
            "[torch.FloatTensor of size 5]\n",
            "\n",
            "linspace between a and b with n steps: \n",
            "\n",
            "  0\n",
            "  4\n",
            "  8\n",
            " 12\n",
            " 16\n",
            " 20\n",
            "[torch.FloatTensor of size 6]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fnkw--V131JU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Tensor Data Types \n",
        "\n",
        "(https://pytorch.org/docs/stable/tensor_attributes.html) \n",
        "\n",
        "\n",
        "Common ones we work with: \n",
        "\n",
        "**FloatTensor** : Equivalent to numpy.float32\n",
        "\n",
        "\n",
        "**LongTensor** : Equivalent to numpy.int64\n"
      ]
    },
    {
      "metadata": {
        "id": "mAMoOx_J6B9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "d70bce38-ad18-4288-8649-5db6d54e640f"
      },
      "cell_type": "code",
      "source": [
        "x = torch.randn([2,3])\n",
        "print(\"Original x: \")\n",
        "print(x)\n",
        "# convert floattensor to long tensor\n",
        "\n",
        "x = x.type(torch.LongTensor)\n",
        "print(\"Datatype modified x: \")\n",
        "print(x)\n",
        "\n",
        "\n",
        "# converting data type of a tensor based on another tensor\n",
        "y = torch.rand([2,2])\n",
        "print(\"Original y: \")\n",
        "print(y)\n",
        "\n",
        "y = y.type_as(x) # tensor x used as reference to change dtype\n",
        "print(\"Datatype of y modified based on x: \")\n",
        "print(y)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original x: \n",
            "\n",
            "-0.4023  0.0972 -0.5682\n",
            "-1.2692  0.5789 -1.5181\n",
            "[torch.FloatTensor of size 2x3]\n",
            "\n",
            "Datatype modified x: \n",
            "\n",
            " 0  0  0\n",
            "-1  0 -1\n",
            "[torch.LongTensor of size 2x3]\n",
            "\n",
            "Original y: \n",
            "\n",
            " 0.0458  0.1755\n",
            " 0.6177  0.8291\n",
            "[torch.FloatTensor of size 2x2]\n",
            "\n",
            "Datatype of y modified based on x: \n",
            "\n",
            " 0  0\n",
            " 0  0\n",
            "[torch.LongTensor of size 2x2]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k4PH0Fi1Dh6C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**_Why is this important?_**\n",
        "\n",
        "-- For operations between tensors, they should strictly have the same data type.\n",
        "\n",
        "-- Certain functions are also very specific about the datatypes"
      ]
    },
    {
      "metadata": {
        "id": "76viOsmMDmhr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Indexing Tensors\n",
        "\n",
        "Very similar to numpy indexing"
      ]
    },
    {
      "metadata": {
        "id": "RqQaXdzHE8jy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "a371a684-a57e-4f98-f683-2d8cbbc9bc4a"
      },
      "cell_type": "code",
      "source": [
        "## 2D tensor\n",
        "\n",
        "x = torch.randn(5,3).type(torch.FloatTensor)\n",
        "print(x)\n",
        "\n",
        "print(\"Indexing the second column\")\n",
        "print(x[:,1])\n",
        "\n",
        "print(\"Indexing the 2nd element of the 4th row\")\n",
        "print(x[3,1])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 1.1125 -0.7474  1.4220\n",
            "-0.5941  0.7546  0.5748\n",
            "-0.8063  0.6410  0.7828\n",
            " 1.6251  0.1756 -0.8472\n",
            "-0.8448 -0.8347 -0.7278\n",
            "[torch.FloatTensor of size 5x3]\n",
            "\n",
            "Indexing the second column\n",
            "\n",
            "-0.7474\n",
            " 0.7546\n",
            " 0.6410\n",
            " 0.1756\n",
            "-0.8347\n",
            "[torch.FloatTensor of size 5]\n",
            "\n",
            "Indexing the 2nd element of the 4th row\n",
            "0.17558613419532776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RWOU8dNWGDB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "79c66f1c-f04f-4f2e-8ac4-55098458b35d"
      },
      "cell_type": "code",
      "source": [
        "## 3D tensor\n",
        "\n",
        "y = torch.randn(1,5,3).type(torch.FloatTensor)\n",
        "print(y)\n",
        "\n",
        "print(\"Indexing the 5X3 tensor from y: \")\n",
        "print(y[0,:,:])\n",
        "\n",
        "print(\"Indexing the 1X3 tensor from y:\")\n",
        "print(y[:,0,:])\n",
        "\n",
        "print(\"Indexing the size 3 tensor from y:\")\n",
        "print(y[0,0,:])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "(0 ,.,.) = \n",
            " -0.0602 -0.8961  0.8293\n",
            " -0.5403  0.5956 -0.7712\n",
            "  0.0709 -0.8890 -1.6091\n",
            "  0.5055  0.9108  0.8569\n",
            " -1.0442  0.1758  0.6451\n",
            "[torch.FloatTensor of size 1x5x3]\n",
            "\n",
            "Indexing the 5X3 tensor from y: \n",
            "\n",
            "-0.0602 -0.8961  0.8293\n",
            "-0.5403  0.5956 -0.7712\n",
            " 0.0709 -0.8890 -1.6091\n",
            " 0.5055  0.9108  0.8569\n",
            "-1.0442  0.1758  0.6451\n",
            "[torch.FloatTensor of size 5x3]\n",
            "\n",
            "Indexing the 1X3 tensor from y:\n",
            "\n",
            "-0.0602 -0.8961  0.8293\n",
            "[torch.FloatTensor of size 1x3]\n",
            "\n",
            "Indexing the 3 tensor from y:\n",
            "\n",
            "-0.0602\n",
            "-0.8961\n",
            " 0.8293\n",
            "[torch.FloatTensor of size 3]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rtc6dmL6Hj0a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. Tensor Manipulation "
      ]
    },
    {
      "metadata": {
        "id": "JwhbFiw2Hm0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "497872fc-ff4e-43bf-ff09-4e293118548c"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "x = torch.arange(9)\n",
        "print(x)\n",
        "print(x.shape)\n",
        "\n",
        "\n",
        "# Squeeze and unsqueeze : to add or remove a dimension\n",
        "print(\"Unsqueeze on the first axis to get a row vector: \")\n",
        "x = torch.unsqueeze(x,0) \n",
        "print(x) \n",
        "\n",
        "print(\"Squeeze to get rid of the additional dimension: \")\n",
        "x= torch.squeeze(x,0) # specify squeeze dimension: the dimension we want to get rid of \n",
        "print(x)\n",
        "\n",
        "print(\"Unsqueeze on the second axis to get a column vector: \")\n",
        "x = torch.unsqueeze(x,1) \n",
        "print(x)\n",
        "\n",
        "# View : similar to numpy.reshape\n",
        "print(\"Reshape the tensor: \")\n",
        "x = x.view(3,3) \n",
        "print(x)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 0\n",
            " 1\n",
            " 2\n",
            " 3\n",
            " 4\n",
            " 5\n",
            " 6\n",
            " 7\n",
            " 8\n",
            "[torch.FloatTensor of size 9]\n",
            "\n",
            "torch.Size([9])\n",
            "Unsqueeze on the first axis to get a row vector: \n",
            "\n",
            "    0     1     2     3     4     5     6     7     8\n",
            "[torch.FloatTensor of size 1x9]\n",
            "\n",
            "Squeeze to get rid of the additional dimension: \n",
            "\n",
            " 0\n",
            " 1\n",
            " 2\n",
            " 3\n",
            " 4\n",
            " 5\n",
            " 6\n",
            " 7\n",
            " 8\n",
            "[torch.FloatTensor of size 9]\n",
            "\n",
            "Unsqueeze on the second axis to get a column vector: \n",
            "\n",
            "    0\n",
            "    1\n",
            "    2\n",
            "    3\n",
            "    4\n",
            "    5\n",
            "    6\n",
            "    7\n",
            "    8\n",
            "[torch.FloatTensor of size 9x1]\n",
            "\n",
            "Reshape the tensor: \n",
            "\n",
            " 0  1  2\n",
            " 3  4  5\n",
            " 6  7  8\n",
            "[torch.FloatTensor of size 3x3]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SfbHvsxYQQCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "41ab56d8-1aeb-451d-e95a-dcc4a92cadc3"
      },
      "cell_type": "code",
      "source": [
        "# Concatenation\n",
        "print(\"Concatenate in the 0th dimension:\")\n",
        "print(torch.cat((x,x),0))\n",
        "\n",
        "print(\"Concatenate in the 1st dimension:\")\n",
        "print(torch.cat((x,x),1))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Concatenate in the 0th dimension:\n",
            "\n",
            " 0  1  2\n",
            " 3  4  5\n",
            " 6  7  8\n",
            " 0  1  2\n",
            " 3  4  5\n",
            " 6  7  8\n",
            "[torch.FloatTensor of size 6x3]\n",
            "\n",
            "Concatenate in the 1st dimension:\n",
            "\n",
            " 0  1  2  0  1  2\n",
            " 3  4  5  3  4  5\n",
            " 6  7  8  6  7  8\n",
            "[torch.FloatTensor of size 3x6]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nJFdPX8rQ1AT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "c4b30b79-6d90-4aa7-96ec-feae04cfedf7"
      },
      "cell_type": "code",
      "source": [
        "# Stacking\n",
        "print(\"Stacking on 0th dimension: \")\n",
        "print(torch.stack((x,x),0))\n",
        "\n",
        "print(\"Stacking on first dimension: \")\n",
        "print(torch.stack((x,x),1))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stacking on 0th dimension: \n",
            "\n",
            "(0 ,.,.) = \n",
            "  0  1  2\n",
            "  3  4  5\n",
            "  6  7  8\n",
            "\n",
            "(1 ,.,.) = \n",
            "  0  1  2\n",
            "  3  4  5\n",
            "  6  7  8\n",
            "[torch.FloatTensor of size 2x3x3]\n",
            "\n",
            "Stacking on first dimension: \n",
            "\n",
            "(0 ,.,.) = \n",
            "  0  1  2\n",
            "  0  1  2\n",
            "\n",
            "(1 ,.,.) = \n",
            "  3  4  5\n",
            "  3  4  5\n",
            "\n",
            "(2 ,.,.) = \n",
            "  6  7  8\n",
            "  6  7  8\n",
            "[torch.FloatTensor of size 3x2x3]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w_NebQfeHy1j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 6. Operations on Tensors"
      ]
    },
    {
      "metadata": {
        "id": "ujjiZwaeTZdV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "90e09807-604a-4e86-e993-ed55fea97cc6"
      },
      "cell_type": "code",
      "source": [
        "x= torch.randn(2,3)\n",
        "print(x)\n",
        "\n",
        "print(\"Get absolute values\")\n",
        "print(torch.abs(x))\n",
        "\n",
        "\n",
        "print(\"Get the over all mean\")\n",
        "print(torch.mean(x))\n",
        "\n",
        "\n",
        "print(\"Get the means in the first dimension: \")\n",
        "print(torch.mean(x,0))\n",
        "\n",
        "print(\"Get element wise square: \")\n",
        "print(x.pow(2))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-1.7490  1.3883 -0.1098\n",
            " 1.2384  0.5407  0.5787\n",
            "[torch.FloatTensor of size 2x3]\n",
            "\n",
            "Get absolute values\n",
            "\n",
            " 1.7490  1.3883  0.1098\n",
            " 1.2384  0.5407  0.5787\n",
            "[torch.FloatTensor of size 2x3]\n",
            "\n",
            "Get the over all mean\n",
            "0.3145650302370389\n",
            "Get the means in the first dimension: \n",
            "\n",
            "-0.2553\n",
            " 0.9645\n",
            " 0.2345\n",
            "[torch.FloatTensor of size 3]\n",
            "\n",
            "Get element wise square: \n",
            "\n",
            " 3.0590  1.9274  0.0121\n",
            " 1.5336  0.2924  0.3349\n",
            "[torch.FloatTensor of size 2x3]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wEK9aN3cH5cx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7. Matrix/Vector Operations"
      ]
    },
    {
      "metadata": {
        "id": "OMIbPtMeIIb4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "0dc47c37-c081-44ee-8221-bd6f5a823b19"
      },
      "cell_type": "code",
      "source": [
        "## MATRICES \n",
        "x = torch.ones(2,2)\n",
        "\n",
        "y = torch.rand(2,2)\n",
        "\n",
        "print(x,y)\n",
        "\n",
        "\n",
        "# addition\n",
        "print(\"Sum of x and y: \")\n",
        "Sum = x+y\n",
        "print(Sum)\n",
        "\n",
        "\n",
        "# element wise multiplication\n",
        "print(\"Element wise multiplication of x and y:\")\n",
        "mul = torch.mul(x,y)\n",
        "print(mul)\n",
        "\n",
        "# Matrix multiplication \n",
        "print(\"Matrix multiplication of x and y: \")\n",
        "MatMul = x.mm(y)\n",
        "print(MatMul)\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 1  1\n",
            " 1  1\n",
            "[torch.FloatTensor of size 2x2]\n",
            " \n",
            " 0.8177  0.8756\n",
            " 0.0064  0.5755\n",
            "[torch.FloatTensor of size 2x2]\n",
            "\n",
            "Sum of x and y: \n",
            "\n",
            " 1.8177  1.8756\n",
            " 1.0064  1.5755\n",
            "[torch.FloatTensor of size 2x2]\n",
            "\n",
            "Element wise multiplication of x and y:\n",
            "\n",
            " 0.8177  0.8756\n",
            " 0.0064  0.5755\n",
            "[torch.FloatTensor of size 2x2]\n",
            "\n",
            "Matrix multiplication of x and y: \n",
            "\n",
            " 0.8241  1.4511\n",
            " 0.8241  1.4511\n",
            "[torch.FloatTensor of size 2x2]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-fsAnJLXdhVQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "489642c8-aa02-4f6c-dc0b-87500c010681"
      },
      "cell_type": "code",
      "source": [
        "## VECTORS:\n",
        "\n",
        "x = torch.arange(5)\n",
        "#x= torch.unsqueeze(x,1)\n",
        "print(x)\n",
        "\n",
        "y = torch.arange(1,6)\n",
        "print(y)\n",
        "\n",
        "# inner product\n",
        "print(\"Inner Product: \")\n",
        "inner = torch.dot(x,y) # will produce a scalar. Make sure x and y are of the same size\n",
        "print(inner)\n",
        "\n",
        "\n",
        "# outer product\n",
        "print(\"\\nOuter Product: \")\n",
        "outer = torch.ger(x,y) # will produce a matrix of size size(x) X size(y)\n",
        "print(outer)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 0\n",
            " 1\n",
            " 2\n",
            " 3\n",
            " 4\n",
            "[torch.FloatTensor of size 5]\n",
            "\n",
            "\n",
            " 1\n",
            " 2\n",
            " 3\n",
            " 4\n",
            " 5\n",
            "[torch.FloatTensor of size 5]\n",
            "\n",
            "Inner Product: \n",
            "40.0\n",
            "\n",
            "Outer Product: \n",
            "\n",
            "  0   0   0   0   0\n",
            "  1   2   3   4   5\n",
            "  2   4   6   8  10\n",
            "  3   6   9  12  15\n",
            "  4   8  12  16  20\n",
            "[torch.FloatTensor of size 5x5]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4M00L_mPIIxI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 8. Conversion from and to Numpy"
      ]
    },
    {
      "metadata": {
        "id": "LFaxNKiLINqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "181b1ece-171e-4170-f900-fd3bdf9deaf0"
      },
      "cell_type": "code",
      "source": [
        "x = np.array([[1,2],[3,4]])\n",
        "print(x)\n",
        "print(type(x))\n",
        "\n",
        "\n",
        "\n",
        "# From numpy ndarray to Tensor\n",
        "print(\"\\nConverted to : \")\n",
        "x_tensor = torch.from_numpy(x)\n",
        "print(x_tensor)\n",
        "\n",
        "\n",
        "# From Tensor to numpy ndarray\n",
        "print(\"Converted back to : \")\n",
        "print(x_tensor.numpy())\n",
        "print(type(x_tensor.numpy()))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "Converted to : \n",
            "\n",
            " 1  2\n",
            " 3  4\n",
            "[torch.LongTensor of size 2x2]\n",
            "\n",
            "Converted back to : \n",
            "[[1 2]\n",
            " [3 4]]\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aveb2nTVWEMz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 9. Performance:  Numpy arrays vs Tensors on CPU vs Tensors on GPU "
      ]
    },
    {
      "metadata": {
        "id": "ImcvzgVkWOiC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a27163bd-d985-440e-c497-cebff8e422f5"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# numpy ndarray on CPU\n",
        "print(\"Numpy array on CPU\")\n",
        "x = np.random.random((1,64))\n",
        "y = np.random.random((1000, 64))\n",
        "%timeit z = (x*y).sum(axis=1)\n",
        "\n",
        "# torch Tensor on CPU\n",
        "print(\"Tensor on CPU\")\n",
        "x = torch.from_numpy(x)\n",
        "y = torch.from_numpy(y)\n",
        "%timeit z=(x*y).sum(dim=1)\n",
        "\n",
        "# torch Tensor on GPU\n",
        "print(\"Tensor on GPU\")\n",
        "x, y = x.cuda(), y.cuda()\n",
        "%timeit z = (x*y).sum(dim=1)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numpy array on CPU\n",
            "1000 loops, best of 3: 185 µs per loop\n",
            "Tensor on CPU\n",
            "1000 loops, best of 3: 235 µs per loop\n",
            "Tensor on GPU\n",
            "10000 loops, best of 3: 75.8 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6CJME867IOWV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 10. What are Variables?\n",
        "\n",
        "\n",
        "Autograd package: "
      ]
    },
    {
      "metadata": {
        "id": "ytaeODCQITvq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b9a4700e-994a-4edb-987a-b131789b67ba"
      },
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "x = torch.Tensor([4.0]) #[1,2,3],[3,4,5]\n",
        "print(\"When the shape of x is: \"+str(x.shape))\n",
        "var = Variable(x,requires_grad = True) # can differentiate wrt this # FOCUS MORE\n",
        "print(var)\n",
        "\n",
        "\n",
        "# when the output is scalar\n",
        "y = torch.mean(2*var)\n",
        "\n",
        "print(y)\n",
        "\n",
        "y.backward() # This will throw an error\n",
        "\n",
        "\n",
        "print(var.grad)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "When the shape of x is: torch.Size([1])\n",
            "Variable containing:\n",
            " 4\n",
            "[torch.FloatTensor of size 1]\n",
            "\n",
            "Variable containing:\n",
            " 8\n",
            "[torch.FloatTensor of size 1]\n",
            "\n",
            "Variable containing:\n",
            " 2\n",
            "[torch.FloatTensor of size 1]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i3RVyB4nvxQt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### When x is an m X n Tensor\n",
        "\n",
        "\\begin{equation}\n",
        "x = \n",
        "\\begin{bmatrix}\n",
        "  x_{11} & x_{12} \\\\\n",
        "  x_{21} & x_{22} \n",
        "\\end{bmatrix} \n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "y = mean(2*x)\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        " y = 2 \\times 1/4 \\times (x_{11} +x_{12} +x_{21}+x_{22}  )\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{dy}{dx} = \n",
        "\\begin{bmatrix}\n",
        "  \\frac{\\partial y}{\\partial x_{11}} & \\frac{\\partial y}{\\partial x_{12}} \\\\\n",
        "  \\frac{\\partial y}{\\partial x_{21}} & \\frac{\\partial y}{\\partial x_{22}} \n",
        "\\end{bmatrix} \n",
        "\\end{equation}\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vNY1ThSBvusY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "5e17161e-92d4-4c85-c1c7-43feba2fdf04"
      },
      "cell_type": "code",
      "source": [
        "x = torch.Tensor([[1,2],[3,4]]) #[1,2,3],[3,4,5]\n",
        "print(\"When the shape of x is: \"+str(x.shape))\n",
        "print(\"Wrapping Tensor x into Variable x:\")\n",
        "var = Variable(x,requires_grad = True) # can differentiate wrt this # FOCUS MORE\n",
        "print(var)\n",
        "print(\"Variables essentially tensors but with an ability to \\\n",
        "  utilize autograd package to compute gradients \")\n",
        "\n",
        "\n",
        "# when the output is scalar\n",
        "y = torch.mean(2*var.pow(2))\n",
        "\n",
        "print(y)\n",
        "\n",
        "y.backward() # This will throw an error\n",
        "\n",
        "\n",
        "print(var.grad)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "When the shape of x is: torch.Size([2, 2])\n",
            "Wrapping Tensor x into Variable x:\n",
            "Variable containing:\n",
            " 1  2\n",
            " 3  4\n",
            "[torch.FloatTensor of size 2x2]\n",
            "\n",
            "Variables essentially tensors but with an ability to   utilize autograd package to compute gradients \n",
            "Variable containing:\n",
            " 15\n",
            "[torch.FloatTensor of size 1]\n",
            "\n",
            "Variable containing:\n",
            " 1  2\n",
            " 3  4\n",
            "[torch.FloatTensor of size 2x2]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VliO2r4s3hIa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 11. Activation Functions\n",
        "\n",
        "Activation functions can be found here :** Torch.nn.functional**"
      ]
    },
    {
      "metadata": {
        "id": "w14pCfTC3S_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "f751d026-c79b-49f4-926a-b73d11def76a"
      },
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "x = torch.linspace(-5,5,1000)\n",
        "x = Variable(x)\n",
        "\n",
        "# using activation function \n",
        "y_relu = F.relu(x)\n",
        "y_sigmoid = F.sigmoid(x)\n",
        "y_tanh = F.tanh(x)\n",
        "\n",
        "\n",
        "\n",
        "# plt to visualize these activation function\n",
        "plt.plot(x.data.numpy(), y_relu.data.numpy(), c='red', label='relu')\n",
        "plt.plot(x.data.numpy(), y_sigmoid.data.numpy(), c='blue', label='sigmoid')\n",
        "plt.plot(x.data.numpy(), y_tanh.data.numpy(), c='green', label='tanh')\n",
        "plt.plot()\n",
        "plt.ylim((-1.5, 1.5))\n",
        "plt.title(\"Activation Functions\")\n",
        "plt.legend(loc='best');\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFZCAYAAACizedRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd1876c30f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "y3wWeB9h49yP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"# When the output is non scalar\n",
        "\n",
        "x = Variable(torch.randn(10), requires_grad=True)\n",
        "print(x)\n",
        "y = x ** 2\n",
        "print(y)\n",
        "\n",
        "#grad = torch.randn(10)\n",
        "#print(grad)\n",
        "\n",
        "torch.autograd.backward([y], [x])\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}